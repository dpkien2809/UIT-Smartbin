{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kjm2MNPBYD8v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 14:02:04.196508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 14:02:04.196541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 14:02:04.197333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 14:02:04.202246: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 14:02:04.894555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras import metrics\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import metrics\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import warnings, glob\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u6HQjBwHYF3E"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PXwXChulYMq2"
   },
   "outputs": [],
   "source": [
    "def set_up_strategy():\n",
    "    try:\n",
    "        # Detect and initialize TPU\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print('Running on TPU:', tpu.master())\n",
    "    except ValueError:\n",
    "        # Detect and initialize GPUs\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        print('Running on multiple GPUs')\n",
    "        tpu = None\n",
    "    return strategy, tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKES_Qd7Yfse",
    "outputId": "60030ecc-2053-4778-ccc0-96dceb7d1446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Running on multiple GPUs\n",
      "REPLICAS: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 14:02:05.878301: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-04 14:02:05.878489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-04 14:02:05.902521: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# TPU or GPU detection\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "strategy, tpu = set_up_strategy()\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDhNWJFjYhp4",
    "outputId": "fc59a697-52e2-4d80-a16e-4933be0cc744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7188 files belonging to 6 classes.\n",
      "Using 5751 files for training.\n",
      "Found 7188 files belonging to 6 classes.\n",
      "Using 1437 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Đường dẫn đến thư mục chứa dataset\n",
    "data_dir = \"../../SmartBin/data/raw_data/Garbage_classification_dataset\"\n",
    "\n",
    "# Định nghĩa các tham số cho dataset\n",
    "batch_size = 8 * REPLICAS\n",
    "img_size = (200, 200)\n",
    "CHANNELS = 3\n",
    "N_CLASSES = 5\n",
    "TTA_STEPS = 0 # Do TTA if > 0\n",
    "\n",
    "\n",
    "# Sử dụng image_dataset_from_directory để tạo dataset từ các hình ảnh trong thư mục đã cho\n",
    "train_ds_original = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_size=img_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\")\n",
    "\n",
    "val_ds_original = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_size=img_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EShfpb80YkJt",
    "outputId": "79558730-6a1f-43dc-e912-db74af835900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bouteille_plastique', 'Brique_en_carton', 'Emballage_metallique', 'Ordure_mn++nagn++re', 'Papier_Carton', 'Verre']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "class_names = train_ds_original.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg4Iu7c5YrwA",
    "outputId": "8a134c21-c0d7-40b8-c13c-a7cb5424c7a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 200, 200, 3)\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds_original:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A0eMkpB0YuPs"
   },
   "outputs": [],
   "source": [
    "image, label = next(iter(train_ds_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CZtauC1VYzXM"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds_original.cache().shuffle(1000)\n",
    "val_ds = val_ds_original.cache().shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iqh4-u3xY1i0",
    "outputId": "8172d148-939b-4e0b-98f8-2b5940e84a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds_original.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kfd_oW5pY89N"
   },
   "outputs": [],
   "source": [
    "def data_augment(image, label):\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "\n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6cH4u0CfY_A0"
   },
   "outputs": [],
   "source": [
    "train_ds_augmented =  train_ds_original.map(data_augment)\n",
    "val_ds_augmented =  val_ds_original.map(data_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CLjeNVdVh7N1"
   },
   "outputs": [],
   "source": [
    "train_ds_combined = tf.data.Dataset.concatenate(train_ds_original, train_ds_augmented)\n",
    "val_ds_combined = tf.data.Dataset.concatenate(val_ds_original, val_ds_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 14:02:07.679771: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: sRGB: out of place\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m y_train \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_ds_combined:\n\u001b[1;32m      4\u001b[0m     x_train\u001b[38;5;241m.\u001b[39mappend(images)\n\u001b[1;32m      5\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for images, labels in train_ds_combined:\n",
    "    x_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "# After the loop, concatenate the lists into NumPy arrays\n",
    "x_train = np.concatenate(x_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "\n",
    "x_test= []\n",
    "y_test = []\n",
    "for images, labels in val_ds_combined:\n",
    "    x_test.append(images)\n",
    "    y_test.append(labels)\n",
    "\n",
    "# After the loop, concatenate the lists into NumPy arrays\n",
    "x_test = np.concatenate(x_test)\n",
    "y_test = np.concatenate(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images,labels in val_ds_combined:\n",
    "#     X_test = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import itertools\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "# from keras.optimizers import RMSprop,Adam\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# model = Sequential()\n",
    "# #\n",
    "# model.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n",
    "#                  activation ='relu', input_shape=(200, 200, 3)))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# #\n",
    "# model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n",
    "#                  activation ='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# # fully connected\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation = \"relu\"))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(3, activation = \"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKU1tEAUZA3c"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import keras\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5,5), activation='relu', input_shape=(200, 200, 3))),\n",
    "model.add(BatchNormalization()),\n",
    "model.add(MaxPooling2D(2, 2)),\n",
    "model.add(Conv2D(64, (3,3), activation='relu')),\n",
    "model.add(BatchNormalization()),\n",
    "model.add(MaxPooling2D(2,2)),\n",
    "model.add(Conv2D(128, (3,3), activation='relu')),\n",
    "model.add(BatchNormalization()),\n",
    "model.add(MaxPooling2D(2,2)),\n",
    "model.add(Conv2D(256, (3,3), activation='relu')),\n",
    "model.add(BatchNormalization()),\n",
    "model.add(MaxPooling2D(2,2)),\n",
    "model.add(Conv2D(512, (3,3), activation='relu')),\n",
    "model.add(BatchNormalization()),\n",
    "model.add(MaxPooling2D(2,2)),\n",
    "model.add(Flatten()),\n",
    "model.add(Dense(512, activation='relu')),\n",
    "model.add(BatchNormalization()),\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16\n",
    "# base_model = VGG16(weights = \"imagenet\", include_top=False, \n",
    "#  input_shape = (200,200, 3))\n",
    "# for layer in base_model.layers:\n",
    "#  layer.trainable = False\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense, Flatten\n",
    "# from keras.models import Model\n",
    "# last_layer = base_model.get_layer('block5_pool')\n",
    "# last_output = last_layer.output\n",
    "# x = Flatten()(last_output)\n",
    "# x = Dense(3, activation='softmax', name='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(inputs=base_model.input, outputs=x)\n",
    "# model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # dimesion reduction\n",
    "#         rotation_range=5,  # randomly rotate images in the range 5 degrees\n",
    "#         zoom_range = 0.1, # Randomly zoom image 10%\n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally 10%\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically 10%\n",
    "#         horizontal_flip=False,  # randomly flip images\n",
    "#         vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# datagen.fit()\n",
    "\n",
    "# history = model.fit_generator(datagen.flow(train_ds_combined, batch_size=batch_size),\n",
    "#                               epochs = 20, validation_data =val_ds_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6Ox_VIxRaDm"
   },
   "outputs": [],
   "source": [
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                            factor=0.2,\n",
    "                                            mode = \"min\",\n",
    "                                            min_lr=1e-12,\n",
    "                                            patience=50,\n",
    "                                            verbose=1)\n",
    "\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                       mode= \"min\",\n",
    "                                       patience=50,\n",
    "                                       verbose=1,\n",
    "                                       restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Y4KnMoBRhUo"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6c9jGycZOAM",
    "outputId": "ee0ae947-ccea-491e-a062-24da1a9ebd56"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds_combined, epochs=1,\n",
    "                    validation_data=val_ds_combined,\n",
    "                    callbacks=[early_stopping, reduce_lr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VI78Jg3JZT9k"
   },
   "outputs": [],
   "source": [
    "model.evaluate(val_ds_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojH9JLitRn__"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_ds_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCF-0TFXiWTk"
   },
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifGG-xbOicoE"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert y_test (one-hot encoded) to integer labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_true, np.argmax(model.predict(x_test), axis=1)))\n",
    "\n",
    "# Generate confusion matrix\n",
    "print(confusion_matrix(y_true, np.argmax(model.predict(x_test), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ej-rX12L0a2"
   },
   "outputs": [],
   "source": [
    "model.save('./model3classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.dtype)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
