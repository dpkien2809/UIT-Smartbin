{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y0Bk-B5-Z-sG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 05:57:22.837487: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-28 05:57:22.837547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-28 05:57:22.838667: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-28 05:57:22.847342: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 05:57:24.516199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.src.applications import imagenet_utils\n",
    "# For versions <TF2.13 change the above import to:\n",
    "# from keras.applications import imagenet_utils\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RphNRQPbhUd1"
   },
   "outputs": [],
   "source": [
    "# Values are from table 4.\n",
    "patch_size = 4  # 2x2, for the Transformer blocks.\n",
    "image_size = 256\n",
    "expansion_factor = 2  # expansion factor for the MobileNetV2 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FpT0_FNph8ZK"
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters=16, kernel_size=3, strides=2):\n",
    "    conv_layer = layers.Conv2D(\n",
    "        filters, kernel_size, strides=strides, activation=tf.nn.swish, padding=\"same\"\n",
    "    )\n",
    "    return conv_layer(x)\n",
    "\n",
    "def inverted_residual_block(x, expanded_channels, output_channels, strides=1):\n",
    "    m = layers.Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False)(x)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "    m = tf.nn.swish(m)\n",
    "\n",
    "    if strides == 2:\n",
    "        m = layers.ZeroPadding2D(padding=imagenet_utils.correct_pad(m, 3))(m)\n",
    "    m = layers.DepthwiseConv2D(\n",
    "        3, strides=strides, padding=\"same\" if strides == 1 else \"valid\", use_bias=False\n",
    "    )(m)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "    m = tf.nn.swish(m)\n",
    "\n",
    "    m = layers.Conv2D(output_channels, 1, padding=\"same\", use_bias=False)(m)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "\n",
    "    if tf.math.equal(x.shape[-1], output_channels) and strides == 1:\n",
    "        return layers.Add()([m, x])\n",
    "    return m\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.swish)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def transformer_block(x, transformer_layers, projection_dim, num_heads=2, return_sequences=True):\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.1,)\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add()([x3, x2])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def mobilevit_block(x, num_blocks, projection_dim, strides=1):\n",
    "    # Local projection with convolutions.\n",
    "    local_features = conv_block(x, filters=projection_dim, strides=strides)\n",
    "    local_features = conv_block(\n",
    "        local_features, filters=projection_dim, kernel_size=1, strides=strides\n",
    "    )\n",
    "\n",
    "    # Unfold into patches and then pass through Transformers.\n",
    "    num_patches = int((local_features.shape[1] * local_features.shape[2]) / patch_size)\n",
    "    non_overlapping_patches = layers.Reshape((patch_size, num_patches, projection_dim))(\n",
    "        local_features\n",
    "    )\n",
    "    global_features = transformer_block(\n",
    "        non_overlapping_patches, num_blocks, projection_dim\n",
    "    )\n",
    "\n",
    "    # Fold into conv-like feature-maps.\n",
    "    folded_feature_map = layers.Reshape((*local_features.shape[1:-1], projection_dim))(\n",
    "        global_features\n",
    "    )\n",
    "\n",
    "    # Apply point-wise conv -> concatenate with the input features.\n",
    "    folded_feature_map = conv_block(\n",
    "        folded_feature_map, filters=x.shape[-1], kernel_size=1, strides=strides\n",
    "    )\n",
    "    local_global_features = layers.Concatenate(axis=-1)([x, folded_feature_map])\n",
    "\n",
    "    # Fuse the local and global features using a convoluion layer.\n",
    "    local_global_features = conv_block(\n",
    "        local_global_features, filters=projection_dim, strides=strides\n",
    "    )\n",
    "\n",
    "    return local_global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7cZQTCbiDl7",
    "outputId": "fba74535-26ca-4fbf-82c3-42d246d451fb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 05:57:26.234276: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 05:57:26.234571: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 05:57:26.278563: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 256, 256, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 128, 128, 16)         448       ['rescaling[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)         512       ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 128, 128, 32)         128       ['conv2d_1[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.nn.silu (TFOpLambda)     (None, 128, 128, 32)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " depthwise_conv2d (Depthwis  (None, 128, 128, 32)         288       ['tf.nn.silu[0][0]']          \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 128, 128, 32)         128       ['depthwise_conv2d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_1 (TFOpLambda)   (None, 128, 128, 32)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 16)         512       ['tf.nn.silu_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 128, 128, 16)         64        ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 128, 128, 16)         0         ['batch_normalization_2[0][0]'\n",
      "                                                                    , 'conv2d[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 32)         512       ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128, 128, 32)         128       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_2 (TFOpLambda)   (None, 128, 128, 32)         0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (None, 129, 129, 32)         0         ['tf.nn.silu_2[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (Depthw  (None, 64, 64, 32)           288       ['zero_padding2d[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 64, 64, 32)           128       ['depthwise_conv2d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_3 (TFOpLambda)   (None, 64, 64, 32)           0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 24)           768       ['tf.nn.silu_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 64, 64, 24)           96        ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 48)           1152      ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 64, 64, 48)           192       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_4 (TFOpLambda)   (None, 64, 64, 48)           0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (Depthw  (None, 64, 64, 48)           432       ['tf.nn.silu_4[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 64, 64, 48)           192       ['depthwise_conv2d_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_5 (TFOpLambda)   (None, 64, 64, 48)           0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 24)           1152      ['tf.nn.silu_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 64, 64, 24)           96        ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 64, 64, 24)           0         ['batch_normalization_8[0][0]'\n",
      "                                                                    , 'batch_normalization_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 48)           1152      ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 64, 64, 48)           192       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_6 (TFOpLambda)   (None, 64, 64, 48)           0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (Depthw  (None, 64, 64, 48)           432       ['tf.nn.silu_6[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 64, 64, 48)           192       ['depthwise_conv2d_3[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.silu_7 (TFOpLambda)   (None, 64, 64, 48)           0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 24)           1152      ['tf.nn.silu_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 64, 64, 24)           96        ['conv2d_8[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 64, 64, 24)           0         ['batch_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 64, 64, 48)           1152      ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 64, 64, 48)           192       ['conv2d_9[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.silu_8 (TFOpLambda)   (None, 64, 64, 48)           0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (None, 65, 65, 48)           0         ['tf.nn.silu_8[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (Depthw  (None, 32, 32, 48)           432       ['zero_padding2d_1[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 32, 32, 48)           192       ['depthwise_conv2d_4[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.silu_9 (TFOpLambda)   (None, 32, 32, 48)           0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 48)           2304      ['tf.nn.silu_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 32, 32, 48)           192       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 64)           27712     ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 64)           4160      ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 4, 256, 64)           0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 4, 256, 64)           128       ['reshape[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 4, 256, 64)           33216     ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 4, 256, 64)           0         ['multi_head_attention[0][0]',\n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 4, 256, 64)           128       ['add_3[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4, 256, 128)          8320      ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 4, 256, 128)          0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4, 256, 64)           8256      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 4, 256, 64)           0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 4, 256, 64)           0         ['dropout_1[0][0]',           \n",
      "                                                                     'add_3[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 4, 256, 64)           128       ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 4, 256, 64)           33216     ['layer_normalization_2[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 4, 256, 64)           0         ['multi_head_attention_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_4[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 4, 256, 64)           128       ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4, 256, 128)          8320      ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 4, 256, 128)          0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 4, 256, 64)           8256      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 4, 256, 64)           0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 4, 256, 64)           0         ['dropout_3[0][0]',           \n",
      "                                                                     'add_5[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 32, 32, 64)           0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 48)           3120      ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32, 32, 96)           0         ['batch_normalization_14[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 64)           55360     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 32, 32, 128)          8192      ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 32, 32, 128)          512       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.silu_10 (TFOpLambda)  (None, 32, 32, 128)          0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadd  (None, 33, 33, 128)          0         ['tf.nn.silu_10[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (Depthw  (None, 16, 16, 128)          1152      ['zero_padding2d_2[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 16, 16, 128)          512       ['depthwise_conv2d_5[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.silu_11 (TFOpLambda)  (None, 16, 16, 128)          0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 16, 16, 64)           8192      ['tf.nn.silu_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 16, 16, 64)           256       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 80)           46160     ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 16, 16, 80)           6480      ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 4, 64, 80)            0         ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 4, 64, 80)            160       ['reshape_2[0][0]']           \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 4, 64, 80)            51760     ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 4, 64, 80)            0         ['multi_head_attention_2[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 4, 64, 80)            160       ['add_7[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 4, 64, 160)           12960     ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 4, 64, 160)           0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 4, 64, 80)            12880     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 4, 64, 80)            0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 4, 64, 80)            0         ['dropout_5[0][0]',           \n",
      "                                                                     'add_7[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 4, 64, 80)            160       ['add_8[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 4, 64, 80)            51760     ['layer_normalization_6[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 4, 64, 80)            0         ['multi_head_attention_3[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_8[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 4, 64, 80)            160       ['add_9[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 4, 64, 160)           12960     ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 4, 64, 160)           0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 4, 64, 80)            12880     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 4, 64, 80)            0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 4, 64, 80)            0         ['dropout_7[0][0]',           \n",
      "                                                                     'add_9[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 4, 64, 80)            160       ['add_10[0][0]']              \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 4, 64, 80)            51760     ['layer_normalization_8[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 4, 64, 80)            0         ['multi_head_attention_4[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_10[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, 4, 64, 80)            160       ['add_11[0][0]']              \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 4, 64, 160)           12960     ['layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 4, 64, 160)           0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 4, 64, 80)            12880     ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 4, 64, 80)            0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 4, 64, 80)            0         ['dropout_9[0][0]',           \n",
      "                                                                     'add_11[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 4, 64, 80)            160       ['add_12[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 4, 64, 80)            51760     ['layer_normalization_10[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 4, 64, 80)            0         ['multi_head_attention_5[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_12[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 4, 64, 80)            160       ['add_13[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 4, 64, 160)           12960     ['layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 4, 64, 160)           0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 4, 64, 80)            12880     ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 4, 64, 80)            0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 4, 64, 80)            0         ['dropout_11[0][0]',          \n",
      "                                                                     'add_13[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 16, 16, 80)           0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 16, 16, 64)           5184      ['reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 16, 16, 128)          0         ['batch_normalization_17[0][0]\n",
      " )                                                                  ',                            \n",
      "                                                                     'conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 16, 16, 80)           92240     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 16, 16, 160)          12800     ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 16, 16, 160)          640       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.silu_12 (TFOpLambda)  (None, 16, 16, 160)          0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadd  (None, 17, 17, 160)          0         ['tf.nn.silu_12[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (Depthw  (None, 8, 8, 160)            1440      ['zero_padding2d_3[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 8, 8, 160)            640       ['depthwise_conv2d_6[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.silu_13 (TFOpLambda)  (None, 8, 8, 160)            0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 8, 8, 80)             12800     ['tf.nn.silu_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 8, 8, 80)             320       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 8, 8, 96)             69216     ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 8, 8, 96)             9312      ['conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)         (None, 4, 16, 96)            0         ['conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 4, 16, 96)            192       ['reshape_4[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 4, 16, 96)            74400     ['layer_normalization_12[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 4, 16, 96)            0         ['multi_head_attention_6[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'reshape_4[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 4, 16, 96)            192       ['add_15[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 4, 16, 192)           18624     ['layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 4, 16, 192)           0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 4, 16, 96)            18528     ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 4, 16, 96)            0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 4, 16, 96)            0         ['dropout_13[0][0]',          \n",
      "                                                                     'add_15[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 4, 16, 96)            192       ['add_16[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 4, 16, 96)            74400     ['layer_normalization_14[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 4, 16, 96)            0         ['multi_head_attention_7[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_16[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 4, 16, 96)            192       ['add_17[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 4, 16, 192)           18624     ['layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 4, 16, 192)           0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 4, 16, 96)            18528     ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 4, 16, 96)            0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 4, 16, 96)            0         ['dropout_15[0][0]',          \n",
      "                                                                     'add_17[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 4, 16, 96)            192       ['add_18[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 4, 16, 96)            74400     ['layer_normalization_16[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 4, 16, 96)            0         ['multi_head_attention_8[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_18[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 4, 16, 96)            192       ['add_19[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 4, 16, 192)           18624     ['layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 4, 16, 192)           0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 4, 16, 96)            18528     ['dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 4, 16, 96)            0         ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 4, 16, 96)            0         ['dropout_17[0][0]',          \n",
      "                                                                     'add_19[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)         (None, 8, 8, 96)             0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 8, 8, 80)             7760      ['reshape_5[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 8, 8, 160)            0         ['batch_normalization_20[0][0]\n",
      " )                                                                  ',                            \n",
      "                                                                     'conv2d_25[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 8, 8, 96)             138336    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 8, 8, 320)            31040     ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 320)                  0         ['conv2d_27[0][0]']           \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 6)                    1926      ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1307942 (4.99 MB)\n",
      "Trainable params: 1305398 (4.98 MB)\n",
      "Non-trainable params: 2544 (9.94 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_mobilevit(num_classes=6):\n",
    "    inputs = keras.Input((image_size, image_size, 3))\n",
    "\n",
    "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
    "\n",
    "    # Initial conv-stem -> MV2 block.\n",
    "    x = conv_block(x, filters=16)\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=16 * expansion_factor, output_channels=16\n",
    "    )\n",
    "\n",
    "    # Downsampling with MV2 block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=16 * expansion_factor, output_channels=24, strides=2\n",
    "    )\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=24 * expansion_factor, output_channels=24\n",
    "    )\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=24 * expansion_factor, output_channels=24\n",
    "    )\n",
    "\n",
    "    # First MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=24 * expansion_factor, output_channels=48, strides=2\n",
    "    )\n",
    "    x = mobilevit_block(x, num_blocks=2, projection_dim=64)\n",
    "\n",
    "    # Second MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=64 * expansion_factor, output_channels=64, strides=2\n",
    "    )\n",
    "    x = mobilevit_block(x, num_blocks=4, projection_dim=80)\n",
    "\n",
    "    # Third MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=80 * expansion_factor, output_channels=80, strides=2\n",
    "    )\n",
    "    x = mobilevit_block(x, num_blocks=3, projection_dim=96)\n",
    "    x = conv_block(x, filters=320, kernel_size=1, strides=1)\n",
    "\n",
    "    # Classification head.\n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "mobilevit_xxs = create_mobilevit()\n",
    "mobilevit_xxs.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "92umJinQiIwe"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "auto = tf.data.AUTOTUNE\n",
    "resize_bigger = 280\n",
    "num_classes = 6\n",
    "\n",
    "\n",
    "def preprocess_dataset(is_training=True):\n",
    "    def _pp(image, label):\n",
    "        if is_training:\n",
    "            # Resize to a bigger spatial resolution and take the random\n",
    "            # crops.\n",
    "            image = tf.image.resize(image, (resize_bigger, resize_bigger))\n",
    "            image = tf.image.random_crop(image, (image_size, image_size, 3))\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            label = tf.one_hot(label, depth=num_classes)\n",
    "        else:\n",
    "            image = tf.image.resize(image, (image_size, image_size))\n",
    "        label = tf.one_hot(label, depth=num_classes)\n",
    "        return image, label\n",
    "\n",
    "    return _pp\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset, is_training=True):\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(batch_size * 10)\n",
    "    dataset = dataset.map(preprocess_dataset(is_training), num_parallel_calls=auto)\n",
    "    return dataset.batch(batch_size).prefetch(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5VuWguEe1zi6"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Bc 1: Load v Tin X l D liu\n",
    "# dataset_path = \"/content/drive/MyDrive/Colab Notebooks/cnn/figure/garbage_classification\"\n",
    "\n",
    "# # To mt list ca ng dn ti cc file nh\n",
    "# image_paths = tf.data.Dataset.list_files(dataset_path + \"/*/*\")\n",
    "\n",
    "# # Hm tin x l cho mi nh\n",
    "# def preprocess_image(image_path):\n",
    "#     # c nh t ng dn\n",
    "#     image = tf.io.read_file(image_path)\n",
    "#     # Gii m nh\n",
    "#     image = tf.image.decode_jpeg(image, channels=3)\n",
    "#     # Resize nh v kch thc mong mun\n",
    "#     image = tf.image.resize(image, (image_size, image_size))\n",
    "#     # Normalization\n",
    "#     image = image / 255.0\n",
    "#     return image\n",
    "\n",
    "# # p dng hm tin x l cho tng nh\n",
    "# # dataset = image_paths.map(preprocess_image) `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WNL_VOOTRDsa"
   },
   "outputs": [],
   "source": [
    "dataset_path1 = \"../../SmartBin/data/raw_data/Garbage classification dataset\"\n",
    "# image_paths = tf.data.Dataset.list_files(dataset_path + \"/*/*\")\n",
    "# def preprocess_image(image_path):\n",
    "# # c nh t ng dn\n",
    "# image = tf.io.read_file(image_paths)\n",
    "# # Gii m nh\n",
    "# image = tf.image.decode_jpeg(image, channels=3)\n",
    "# # Resize nh v kch thc mong mun\n",
    "# image = tf.image.resize(image, (image_size, image_size))\n",
    "# # Normalization\n",
    "# image = image / 255.0\n",
    "# return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DT9KgRwQG8p",
    "outputId": "4370fbfb-aad2-4514-e9ff-f53a7bbbff5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7188 files belonging to 6 classes.\n",
      "Using 5751 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds_original = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path1,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVxIcfH9SRJj",
    "outputId": "bd759ed0-836f-4a0c-f3e9-40302bc73fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7188 files belonging to 6 classes.\n",
      "Using 1437 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds_original = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path1,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_WHYPvSdSfdA"
   },
   "outputs": [],
   "source": [
    "X = train_ds_original\n",
    "y = val_ds_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pm58Nm2715Kz"
   },
   "outputs": [],
   "source": [
    "# # Ly s lng nh trong dataset\n",
    "# num_images = len(image_paths)\n",
    "\n",
    "# # Tnh ton s lng nh cho tp validation\n",
    "# num_val_images = int(0.2 * num_images)\n",
    "\n",
    "# # To tp validation v tp train\n",
    "# val_dataset = dataset.take(num_val_images)\n",
    "# train_dataset = dataset.skip(num_val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hFi5fOn7u9tw"
   },
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XixRuJjDvDd9"
   },
   "outputs": [],
   "source": [
    "# X = train_dataset.batch(batch_size).prefetch(auto)\n",
    "# y = val_dataset.batch(batch_size).prefetch(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXWPeqFWiRc6",
    "outputId": "4ac8750d-03ca-4811-e367-ae3120f1a11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 05:58:08.688328: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: sRGB: out of place\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node decode_image/DecodeImage defined at (most recent call last):\n<stack traces unavailable>\nUnknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_42970]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mobilevit_xxs\n\u001b[0;32m---> 35\u001b[0m mobilevit_xxs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/checkpoint6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     15\u001b[0m     checkpoint_filepath,\n\u001b[1;32m     16\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmobilevit_xxs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train_dataset ,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_data=val_dataset,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m mobilevit_xxs\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[1;32m     30\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m mobilevit_xxs\u001b[38;5;241m.\u001b[39mevaluate(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node decode_image/DecodeImage defined at (most recent call last):\n<stack traces unavailable>\nUnknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_42970]"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.002\n",
    "label_smoothing_factor = 0.1\n",
    "epochs = 30\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing_factor)\n",
    "\n",
    "\n",
    "def run_experiment(epochs=epochs):\n",
    "    mobilevit_xxs = create_mobilevit(num_classes=6)\n",
    "    mobilevit_xxs.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint6\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    mobilevit_xxs.fit(\n",
    "        # train_dataset ,\n",
    "        # validation_data=val_dataset,\n",
    "        X,\n",
    "        validation_data = y,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "    mobilevit_xxs.load_weights(checkpoint_filepath)\n",
    "    _, accuracy = mobilevit_xxs.evaluate(y)\n",
    "    print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    return mobilevit_xxs\n",
    "\n",
    "\n",
    "mobilevit_xxs = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgrsE8VWiUar"
   },
   "outputs": [],
   "source": [
    "# Serialize the model as a SavedModel.\n",
    "# mobilevit_xxs.save(\"mobilevit_xxs_3classes_3\")\n",
    "\n",
    "# Convert to TFLite. This form of quantization is called\n",
    "# post-training dynamic-range quantization in TFLite.\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"mobilevit_xxs_3classes_3\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,  # Enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "open(\"mobilevit_xxs_3classes_3.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = keras.models.load_model(\"mobilevit_xxs_3classes_3\")\n",
    "\n",
    "# Create a list to store true labels and predicted labels\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "# Iterate over the validation dataset to obtain true and predicted labels\n",
    "for images, labels in y:\n",
    "    y_true_list.extend(np.argmax(labels, axis=1))\n",
    "    y_pred = np.argmax(loaded_model.predict(images), axis=1)\n",
    "    y_pred_list.extend(y_pred)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "y_true = np.array(y_true_list)\n",
    "y_pred = np.array(y_pred_list)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
